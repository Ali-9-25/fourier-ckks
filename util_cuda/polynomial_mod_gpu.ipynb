{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-19T22:43:10.493883Z",
     "iopub.status.busy": "2025-04-19T22:43:10.493223Z",
     "iopub.status.idle": "2025-04-19T22:43:10.497956Z",
     "shell.execute_reply": "2025-04-19T22:43:10.497314Z",
     "shell.execute_reply.started": "2025-04-19T22:43:10.493855Z"
    },
    "id": "iFtsTcDPOyn9",
    "outputId": "b6150f86-4262-47b4-8153-976343a166bc",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Setup cuda environment\n",
    "# !pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
    "# %load_ext nvcc4jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89sBrBJ-OzrL"
   },
   "source": [
    "### **Resources**\n",
    "\n",
    "*   https://developer.nvidia.com/blog/how-optimize-data-transfers-cuda-cc/\n",
    "*   https://developer.nvidia.com/blog/how-overlap-data-transfers-cuda-cc/#overlapping_kernel_execution_and_data_transfers\n",
    "*   https://developer.nvidia.com/blog/gpu-pro-tip-cuda-7-streams-simplify-concurrency/\n",
    "*   https://vitalitylearning.medium.com/using-c-c-and-cuda-functions-as-regular-python-functions-716f01f7ca22\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T12:51:11.778615Z",
     "iopub.status.busy": "2025-04-20T12:51:11.778162Z",
     "iopub.status.idle": "2025-04-20T12:51:11.789405Z",
     "shell.execute_reply": "2025-04-20T12:51:11.788698Z",
     "shell.execute_reply.started": "2025-04-20T12:51:11.778590Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing polyModGPU.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile polyModGPU.cu\n",
    "#include <cstdio>\n",
    "#include <iostream>\n",
    "#define CUDA_CHECK(call)                                                     \\\n",
    "  do {                                                                        \\\n",
    "    cudaError_t err = call;                                                   \\\n",
    "    if (err != cudaSuccess) {                                                 \\\n",
    "      fprintf(stderr, \"CUDA error at %s:%d: %s\\n\",                            \\\n",
    "              __FILE__, __LINE__, cudaGetErrorString(err));                   \\\n",
    "      exit(EXIT_FAILURE);                                                     \\\n",
    "    }                                                                         \\\n",
    "  } while (0)\n",
    "\n",
    "// CUDA kernel function\n",
    "__global__ void polynomial_mod_kernel(int *polynomial, int size, int coeff_mod) {\n",
    "    int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
    "    int stride = gridDim.x * blockDim.x;\n",
    "    for (; tid < size; tid += stride) {\n",
    "        polynomial[tid] %= coeff_mod;\n",
    "    }\n",
    "}\n",
    "\n",
    "// Wrapper function to call the CUDA kernel\n",
    "extern \"C\" void polynomial_mod(int *polynomial, int size, int coeff_mod) {\n",
    "    // Allocate device memory\n",
    "    int *d_polynomial = nullptr;\n",
    "    CUDA_CHECK(cudaMalloc((void**)&d_polynomial, size * sizeof(int)));\n",
    "\n",
    "    // Copy input data to device\n",
    "    CUDA_CHECK(cudaMemcpy(d_polynomial, polynomial, size * sizeof(int), cudaMemcpyHostToDevice));\n",
    "\n",
    "    // Launch CUDA kernel\n",
    "    int threadsPerBlock = 256;\n",
    "    int blocksPerGrid = (size + threadsPerBlock - 1) / threadsPerBlock;\n",
    "\n",
    "    // Query max active blocks per multiprocessor\n",
    "    int device;\n",
    "    CUDA_CHECK(cudaGetDevice(&device));\n",
    "\n",
    "    cudaFuncAttributes attr;\n",
    "    CUDA_CHECK(cudaFuncGetAttributes(&attr, polynomial_mod_kernel));\n",
    "\n",
    "    cudaDeviceProp prop;\n",
    "    CUDA_CHECK(cudaGetDeviceProperties(&prop, device));\n",
    "\n",
    "    std::cout << prop.maxGridSize[0];\n",
    "    // In case number of needed blocks exceeds hardware limit\n",
    "    blocksPerGrid = std::min(blocksPerGrid, prop.maxGridSize[0]);\n",
    "    \n",
    "    polynomial_mod_kernel<<<blocksPerGrid, threadsPerBlock>>>(d_polynomial, size, coeff_mod);\n",
    "\n",
    "    CUDA_CHECK(cudaDeviceSynchronize());\n",
    "    //CUDA_CHECK(cudaDeviceSynchronize());\n",
    "    // Copy result back to host\n",
    "    CUDA_CHECK(cudaMemcpy(polynomial, d_polynomial, size * sizeof(int), cudaMemcpyDeviceToHost));\n",
    "\n",
    "    // Free device memory\n",
    "    CUDA_CHECK(cudaFree(d_polynomial));\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T12:53:30.031728Z",
     "iopub.status.busy": "2025-04-20T12:53:30.031071Z",
     "iopub.status.idle": "2025-04-20T12:53:32.927460Z",
     "shell.execute_reply": "2025-04-20T12:53:32.926691Z",
     "shell.execute_reply.started": "2025-04-20T12:53:30.031705Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Compile the cuda code and produce a shared library to get linked to the python main program\n",
    "!nvcc -shared -Xcompiler -fPIC -o polyModGPU.so polyModGPU.cu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Polynomial Modulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T23:12:53.055049Z",
     "iopub.status.busy": "2025-04-19T23:12:53.054805Z",
     "iopub.status.idle": "2025-04-19T23:12:53.061712Z",
     "shell.execute_reply": "2025-04-19T23:12:53.060934Z",
     "shell.execute_reply.started": "2025-04-19T23:12:53.055033Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2147483647Coeff_mod: 9\n",
      "Result: [1, 2, 3, 4, 8, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# Python function calling the compiled C++/CUDA function\n",
    "\n",
    "\n",
    "# ctypes in python bridges the gap between python dynamic data types and c static ones.\n",
    "import ctypes\n",
    "\n",
    "# Load the CUDA library\n",
    "cuda_lib = ctypes.CDLL('./polyModGPU.so')  # Update with the correct path\n",
    "\n",
    "# Define the function prototype\n",
    "cuda_lib.polynomial_mod.argtypes = [ctypes.POINTER(ctypes.c_int), ctypes.c_int, ctypes.c_int]\n",
    "cuda_lib.polynomial_mod.restype = None\n",
    "# cuda_lib.my_cuda_function.restype = None\n",
    "\n",
    "# Prepare data\n",
    "polynomial_coeff = [1, 2, 3, 4, 8 ,9 ,10]\n",
    "size = len(polynomial_coeff)\n",
    "coeff_mod = 9\n",
    "\n",
    "# Convert Python lists to ctypes arrays\n",
    "polynomial_array = (ctypes.c_int * size)(*polynomial_coeff)\n",
    "\n",
    "# Call the CUDA function\n",
    "cuda_lib.polynomial_mod(polynomial_array, size, coeff_mod)\n",
    "\n",
    "# Print the result\n",
    "result = list(polynomial_array)\n",
    "print('Coeff_mod:',coeff_mod )\n",
    "print(\"Result:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Large Input Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T23:14:58.180783Z",
     "iopub.status.busy": "2025-04-19T23:14:58.180498Z",
     "iopub.status.idle": "2025-04-19T23:14:58.453475Z",
     "shell.execute_reply": "2025-04-19T23:14:58.452705Z",
     "shell.execute_reply.started": "2025-04-19T23:14:58.180757Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2147483647First 10 results: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Last 10 results:  [17, 18, 19, 20, 21, 22, 23, 24, 25, 26]\n"
     ]
    }
   ],
   "source": [
    "import ctypes\n",
    "import math\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1) Load your CUDA library and define its prototype\n",
    "# -----------------------------------------------------------------------------\n",
    "cuda_lib = ctypes.CDLL('./polyModGPU.so')  \n",
    "cuda_lib.polynomial_mod.argtypes = [\n",
    "    ctypes.POINTER(ctypes.c_int),  # int *polynomial\n",
    "    ctypes.c_int,                  # int   size\n",
    "    ctypes.c_int,                  # int   coeff_mod\n",
    "]\n",
    "cuda_lib.polynomial_mod.restype = None\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2) Define your device‐limit constants (tweak these to match your GPU)\n",
    "#    On most cards:\n",
    "#      maxThreadsPerBlock  = 1024 (but you chose 256 in your kernel)\n",
    "#      maxGridSize[0]      ~ 2^31−1\n",
    "# -----------------------------------------------------------------------------\n",
    "MAX_THREADS_PER_BLOCK   = 256\n",
    "MAX_BLOCKS_PER_GRID     = 2**16    # a safe “minimum” for modern GPUs; you can query prop.maxGridSize[0] if you like\n",
    "MAX_ELEMS_PER_LAUNCH    = MAX_THREADS_PER_BLOCK * MAX_BLOCKS_PER_GRID\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3) The “big‐array” wrapper\n",
    "# -----------------------------------------------------------------------------\n",
    "def polynomial_mod_large(polynomial: list[int], coeff_mod: int) -> None:\n",
    "    \"\"\"\n",
    "    Applies polynomial_mod() in‑place over an arbitrarily large Python list\n",
    "    by splitting it into chunks no bigger than MAX_ELEMS_PER_LAUNCH.\n",
    "    \"\"\"\n",
    "    total = len(polynomial)\n",
    "    polynomial_array = (ctypes.c_int * total)(*polynomial)\n",
    "\n",
    "    # call the CUDA kernel on just this slice\n",
    "    cuda_lib.polynomial_mod(polynomial_array, total, coeff_mod)\n",
    "\n",
    "    # copy results back into our Python list\n",
    "    polynomial = list(polynomial_array)\n",
    "    return polynomial\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4) Usage example\n",
    "# -----------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # some huge polynomial:\n",
    "    poly = list(range(1_000_000))  # 1 million coefficients\n",
    "    # poly = list(range(22_000_000_00))  # GPU limit is 2147483647 or 2^31 − 1\n",
    "    mod  = 97\n",
    "\n",
    "    result = polynomial_mod_large(poly, mod)\n",
    "    print(\"First 10 results:\", result[:10])\n",
    "    print(\"Last 10 results: \", result[-10:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T12:54:58.290694Z",
     "iopub.status.busy": "2025-04-20T12:54:58.290000Z",
     "iopub.status.idle": "2025-04-20T12:54:58.298280Z",
     "shell.execute_reply": "2025-04-20T12:54:58.297685Z",
     "shell.execute_reply.started": "2025-04-20T12:54:58.290671Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: [[10, 11, 12, 13], [20, 21, 22, 23], [30, 31, 32, 33]]\n",
      "Modded  : [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]]\n"
     ]
    }
   ],
   "source": [
    "import ctypes\n",
    "import math\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1) Load your CUDA library and define its prototype\n",
    "# -----------------------------------------------------------------------------\n",
    "cuda_lib = ctypes.CDLL('./polyModGPU.so')  \n",
    "cuda_lib.polynomial_mod.argtypes = [\n",
    "    ctypes.POINTER(ctypes.c_int),  # int *polynomial\n",
    "    ctypes.c_int,                  # int   size\n",
    "    ctypes.c_int,                  # int   coeff_mod\n",
    "]\n",
    "cuda_lib.polynomial_mod.restype = None\n",
    "def polynomial_mod_batch(polynomials, degree, coeff_mod):\n",
    "    # 1. Validate input\n",
    "    if not polynomials or degree <= 0:\n",
    "        return []\n",
    "\n",
    "    # 2. Flatten list of polynomials\n",
    "    flat_list = []\n",
    "    length_polynomial = degree + 1\n",
    "    for poly in polynomials:\n",
    "        if len(poly) != length_polynomial:\n",
    "            raise ValueError(f\"Expected each polynomial to have degree {degree}, got {len(poly)}.\")\n",
    "        flat_list.extend(poly)\n",
    "\n",
    "    total_size = len(flat_list)\n",
    "\n",
    "    # 3. Convert to ctypes array\n",
    "    flat_array = (ctypes.c_int * total_size)(*flat_list)\n",
    "\n",
    "    # 4. Call the CUDA kernel\n",
    "    cuda_lib.polynomial_mod(flat_array, total_size, coeff_mod)\n",
    "\n",
    "    # 5. Convert result back to list of polynomials\n",
    "    result = list(flat_array)\n",
    "    num_polynomials = len(polynomials)\n",
    "    result_polynomials = [\n",
    "        result[i * length_polynomial : (i + 1) * length_polynomial]\n",
    "        for i in range(num_polynomials)\n",
    "    ]\n",
    "\n",
    "    return result_polynomials\n",
    "\n",
    "# ------------------ Example Usage ------------------\n",
    "if __name__ == \"__main__\":\n",
    "    polys = [\n",
    "        [10, 11, 12, 13],\n",
    "        [20, 21, 22, 23],\n",
    "        [30, 31, 32, 33]\n",
    "    ]\n",
    "    coeff_mod = 10\n",
    "    degree = 3\n",
    "\n",
    "    result = polynomial_mod_batch(polys, degree, coeff_mod)\n",
    "    print(\"Original:\", polys)\n",
    "    print(\"Modded  :\", result)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
